model_list:
  # ===== MODELOS PREMIUM (Alta capacidad, mayor costo) =====
  
  # Claude Sonnet 4 - Excelente para razonamiento complejo y coding
  - model_name: claude-sonnet-4
    litellm_params:
      model: anthropic/claude-sonnet-4-20250514
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 8192
  
  # Claude Opus 4 - El más potente para tareas extremadamente complejas
  - model_name: claude-opus-4
    litellm_params:
      model: anthropic/claude-opus-4-20250514
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 8192
  
  # GPT-4o - Balanceado, rápido y multimodal
  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 4096
  
  # GPT-4.5 - Lo más avanzado de OpenAI (requiere Pro)
  - model_name: gpt-4.5
    litellm_params:
      model: openai/gpt-4.5-turbo
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 4096
  
  # o1 - Especializado en razonamiento profundo
  - model_name: o1
    litellm_params:
      model: openai/o1
      api_key: os.environ/OPENAI_API_KEY
  
  # ===== MODELOS MID-RANGE (Balance precio-rendimiento) =====
  
  # Claude 3.5 Sonnet - Anterior generación pero muy capaz
  - model_name: claude-3.5-sonnet
    litellm_params:
      model: anthropic/claude-3-5-sonnet-20241022
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 8192
  
  # GPT-4o Mini - Rápido y económico de OpenAI
  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 4096
  
  # Gemini 2.0 Pro - Excelente para multimodal
  - model_name: gemini-2-pro
    litellm_params:
      model: gemini/gemini-2.0-pro
      api_key: os.environ/GEMINI_API_KEY
  
  # ===== MODELOS ECONÓMICOS (Mejor costo, gran velocidad) =====
  
  # Gemini 2.0 Flash - Súper rápido y barato ($0.40/M tokens)
  - model_name: gemini-2-flash
    litellm_params:
      model: gemini/gemini-2.0-flash-exp
      api_key: os.environ/GEMINI_API_KEY
  
  # Claude 3 Haiku - Rápido y económico de Anthropic
  - model_name: claude-3-haiku
    litellm_params:
      model: anthropic/claude-3-haiku-20240307
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 4096
  
  # DeepSeek V3 - Extremadamente económico ($0.27/M tokens input)
  - model_name: deepseek-v3
    litellm_params:
      model: deepseek/deepseek-chat
      api_key: os.environ/DEEPSEEK_API_KEY
  
  # ===== MODELOS ESPECIALIZADOS =====
  
  # GPT-4 Vision - Para análisis de imágenes
  - model_name: gpt-4-vision
    litellm_params:
      model: openai/gpt-4-vision-preview
      api_key: os.environ/OPENAI_API_KEY
  
  # Gemini Pro Vision - Multimodal de Google
  - model_name: gemini-pro-vision
    litellm_params:
      model: gemini/gemini-pro-vision
      api_key: os.environ/GEMINI_API_KEY
  
  # Mistral Large - Europeo, potente y rápido
  - model_name: mistral-large
    litellm_params:
      model: mistral/mistral-large-latest
      api_key: os.environ/MISTRAL_API_KEY
  
  # Mistral Medium - Balance de Mistral
  - model_name: mistral-medium
    litellm_params:
      model: mistral/mistral-medium-latest
      api_key: os.environ/MISTRAL_API_KEY
  
  # ===== MODELOS OPEN SOURCE (vía APIs) =====
  
  # Llama 3.1 70B - Potente y open source
  - model_name: llama-3.1-70b
    litellm_params:
      model: together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo
      api_key: os.environ/TOGETHER_API_KEY
  
  # Llama 3.1 8B - Rápido y económico
  - model_name: llama-3.1-8b
    litellm_params:
      model: together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
      api_key: os.environ/TOGETHER_API_KEY

# ===== CONFIGURACIÓN GENERAL =====
litellm_settings:
  drop_params: true  # Ignora parámetros no soportados
  success_callback: ["langfuse"]  # Para tracking (opcional)
  failure_callback: ["langfuse"]
  
router_settings:
  routing_strategy: simple-shuffle  # Balancea carga
  allowed_fails: 3  # Reintentos antes de fallar
  cooldown_time: 30  # Tiempo de cooldown tras falla

general_settings:
  master_key: "sk-myworkin-2026-replace-with-secure-key"  # ⚠️ CAMBIA ESTO
  database_url: "os.environ/DATABASE_URL"  # Opcional: para tracking de uso
  
# ===== CONFIGURACIÓN DE CALLBACKS (Opcional) =====
# Descomenta si quieres tracking avanzado con Langfuse
# litellm_settings:
#   callbacks: ["langfuse"]
#   langfuse_public_key: "os.environ/LANGFUSE_PUBLIC_KEY"
#   langfuse_secret_key: "os.environ/LANGFUSE_SECRET_KEY"
